---
title: "Credit Card Fraud Detection"
author: "Truc Huynh"
output: powerpoint_presentation
css: style.css
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE, warning=FALSE)
#library to use for the analysis
library(psych)
library(e1071)
library(rpart)
library(randomForest)
library(caTools)
library(rpart.plot)
library(readr)
library(caret)
library(RColorBrewer)
```

## Abstract

- The project focus on creating Fraud Detection Application to detect fraudulent credit card transactions
- The increase in non-cash transactions leads to an increase in fraudulent transactions (Macaraeg, 2019). 
- Implemented fraud detection (using data mining) is important.  

## Motivation

- Using data mining to mitigate the risk of fraudulent, 
- Fraud detection is an interesting data mining project because it fights against criminal issues. 
- Application can be used by credit card companies to stop fraudulent transactions at real time.
- Design and test Machine Learning ALgorithm to find the interesting pattern to prevent fraud-transactions  
- Learn new methods (Predictive Model, Classification, Clustering…) and apply them to solve the problem.

## Data Description

- Data is highly unbalanced (99.83% non-fraud vs. 0.17% fraud). This makes it hard to subset and train data (sampling). 
- The variables named v1 to v28 in order to maintain the privacy of the credit card users (Machine Learning Group, 2018).
- Data can be download at <a href="https://www.kaggle.com/mlg-ulb/creditcardfraud"> kaggle.com</a>

## Approach

- The learning goals
- Sampling data, selecting variables
- Data pre-processing for sequence information
- Selection of useful attributes
- Goals matched with DM methods
- Selection of data model(s), and method(s)
- Review and ask for feedback to improve
- Generate pattern (Data Mining)
- Interpret the model(s) based on visualization
- Integrate all discovered knowledge into reports, resolve any conflicts as needed
- Final Review & Improve base on given feedback

## Problem Statement 

- The data set is highly unbalanced (positive class (frauds) account for 0.172% of all transactions). 
- Create a meaningful subset.
- Data Visualization, Confusion Matrix, Clustering Methods, and Decision Tree to detect meaningful patterns in fraudulent credit card transactions.

## Patil. S., Nemade. V., & Soni, P. (Predictive Modelling)

<p>
- Designing a framework for data pre-processing.
- Designing an analytical model for fraud prediction (approach misuse detection and anomaly detection)
      <ol>
        <li><b class="design">Logistic regression.</b></li>
        <li><b class="design">Decision tree:</b> The  decision  tree  uses  <b>ID3  technique</b>  for  building  decision  tree  by  considering entropy of dataset</li>
        <li><b class="design">Random Forest Decision Tree:</b> are supervised learning algorithms used for both classification and regression problems. These two algorithms are best explained together because random forests are a bunch of decision trees combined.</li>
      </ol>
</p>      

## Gabriel Preda (Machine Learning)

- <i>Accoring to Preda (2020)</i>, his work included investigated the data, checking for data unbalancing, visualizing the features, and understanding the relationship between different features. He then investigated two predictive models. The data was split into 3 parts, a train set, a validation set, and a test set. For the first three models, He only used the train and test set.
      <ol>
        <li><b class="design">RandomForrestClassifier:</b> obtain AUC score of <b>0.85</b></li>
        <li><b class="design">AdaBoostClassifier model:</b> obtain AUC score <b>(0.83)</b></li>
        <li><b class="design">CatBoostClassifier:</b> obtain AUC score <b>0.86</b> </li>
        <li><b class="design">XGBoost model:</b> validation score obtained was <b>0.984</b> </li>
        <li><b class="design">LightGBM model:</b> used both train-validation split and cross-validation to evaluate the model. Obtain <b>0.974 (training set)</b> and <b>0.946 (test)</b> </li>
      </ol>
</br>



## Pavan Sanagapati (Outliers)

- <b class="serif"><i>Anomaly detection</b></i> is a technique used to identify unusual patterns that do not conform to expected behavior, called outliers (Sanagapati, 2019).Anomaly detection (also outlier detection) is the identification of rare items, events, or observations that raise suspicions by differing significantly from the majority of the data.
- Method used:
  <ol>
    <li><b class="design">Isolation Forest algorithm:</b> an unsupervised machine learning algorithm that identifies anomaly by isolating outliers in the data.</li>
    <li><b class="design">Local Outlier Factor (LOF) algorithm:</b> unsupervised anomaly detection method which computes the local density deviation of a given data point concerning its neighbors.</li>
    <li><b class="design">Support Vector Machine (SVM) model:</b> a supervised machine learning model that uses classification algorithms for two-group classification problems.</li>
  </ol>
  </br>

## Data Description

- Source: "https://www.kaggle.com/mlg-ulb/creditcardfraud"
- Size:
```{r data, echo = TRUE}
# Import Data
Rdata <- read.csv("~/R/DataMining/FaultAnalyst.CreditCard/data/data.csv", header=TRUE)

# Number of Rows
nrow(Rdata)

# Number of Columns
ncol(Rdata)
```
- Attributes
<p>
  <ul>
    <li>Time: Number of seconds elapsed between this transaction and the first transaction in the dataset.</li>
    <li>V1 to V28: may be result of a PCA Dimensionality reduction to protect user identities and sensitive features(v1-v28)</li>
    <li>Amount: Transaction amount</li>
    <li>Class: 1 for fraudulent transactions, 0 otherwise</li>
  </ul>
<p>

## Main characters

```{r mainCharacters}
# data exploration
str(Rdata)
```

## Data Exploration 

- Explore mean, standard deviation, correlation, and else using <b>describe</b> function.</br>
```{r describe}
#Explore the data
describe(Rdata)  
```

## Validation and Summary

- Number of missing data in the data frame 
```{r explore, echo=TRUE}
# check if data contain empty variable
sum(is.na(Rdata))
mean(is.na(Rdata))

#Explore the data
summary(Rdata) 
```
```{r descriptionPrint}
help_console <-
  function(topic,
           format = c("text", "html", "latex", "Rd"),
           lines = NULL,
           before = NULL,
           after = NULL) {
    format = match.arg(format)
    if (!is.character(topic))
      topic <- deparse(substitute(topic))
    helpfile = utils:::.getHelpFile(help(topic))
    
    hs <- capture.output(switch(
      format,
      text = tools:::Rd2txt(helpfile),
      html = tools:::Rd2HTML(helpfile),
      latex = tools:::Rd2latex(helpfile),
      Rd = tools:::prepare_Rd(helpfile)
    ))
    if (!is.null(lines))
      hs <- hs[lines]
    hs <- c(before, hs, after)
    cat(hs, sep = "\n")
    invisible(hs)
  }
```

## Subset data

- <b>Subset:</b> subset the original data in the ratio of 7:3 <b>Train Data Set of 70% (Big_Train)</b> of original data set and <b>test data set of 30% (Big_Test) </b>
- <b>Sampling: </b> Sampling subset will include all the fraud transaction and 10,000 rows of normal transaction to test the accurate of SVM and Random Forest.Then subset the sampling data set in to <b>subset train data set(0.7) (Small_Train)</b> and <b>subset test data set(0.3) (Small_Test)</b>
```{r subset}
# Predictive Modeling
# Prepare Data for training
# Split data 70:30
Rdata$Class <- factor(Rdata$Class)

set.seed(1)
# Split data from vector data$Class into two sets in predefined ratio while preserving
# relative ratios of different labels in data$Class. Used to split the data used during
# classification into train and test subsets.
split <- sample.split(Rdata$Class, SplitRatio = 0.7)

train <- subset(Rdata, split == T) # train data set of the original data

cv <- subset(Rdata, split == F) # test data set of the original data

# CREATE SMALL SUBSET of the ORIGINAL
# Collect all normal transaction in the original data set
data.class.0 <- subset(Rdata, Rdata$Class == 0)

# Collect all fraud transaction in the original data set
data.class.1 <- subset(Rdata, Rdata$Class == 1)

# Get only 10,000 line of the normal transaction in the original data set
data.class.0 <- data.class.0[1:10000, ]

# Create the Subset Data
subsetData <- rbind(data.class.0, data.class.1)

rm(data.class.0,data.class.1) # Clean up/ un-use variable

set.seed(10)
split <- sample.split(subsetData$Class, SplitRatio = 0.7)
train.subset <- subset(subsetData, split == T)
cv.subset <- subset(subsetData, split == F)
```
- Subset from Original:
```{r subset1, echo=TRUE}
# Train dataset(0.7) and test data set(0.3)
nrow(train) # train
nrow(cv) # test
```
- Subset from Sampling
```{r subset2, echo=TRUE}
# Subset train dataset(0.7) and subset test data set(0.3)
nrow(train.subset) # train
nrow(cv.subset) # test

```



## Data Visualization

- To get a general idea about the data 
- To draw hypothesis
- Algorithm
<ul>
  <li>Simply convert the Time in the data set to twenty-four hours time system. The purpose is to estimate what time fraud transaction amount usually occur</li>
  <li>geom_density() function of ggplot2 package</li>
  <li>ggplot() function of ggplot2 package</li>
</ul>
```{r visualPreparation}
#Copy the Rdata to DisplayData
DisplayData<- Rdata

DisplayData$hour_of_day <- (DisplayData$Time/3600) %% 24 # convert to hours, then reduce mod 24
# to display only
DisplayData$Class <- factor(ifelse(DisplayData$Class == 0, "zero", "one")) # creates issues later in caret if using 0, 1
```
</br>

## Transaction's Hour Density Chart

```{r transHoursPlot , fig.width=10, fig.height=5}
ggplot(DisplayData, aes(x = hour_of_day, fill = Class)) +
  geom_density(alpha = 0.4) + 
  scale_x_continuous(limits = c(0, 24), breaks = seq(0, 24, 2)) + 
  labs(title = "Transaction's Hour", 
       x = "Hours", 
       y = "Density", 
       col = "Class") + 
  scale_fill_discrete(labels = c("Fraud", "Not Fraud"))
```
</br>
- Evaluation:
<ol>
  <li>Fraud transaction are happened from <b>0 to 8 AM</b> (early morning and during sleep time)</li>
  <li>Non-fraud transaction happen during nornal active-time (business hours)</li> 
  <li>This is also a common sense since human usually purchase in the day-time, not when they sleep</li>
  <li>Hypothesis: transactions happen at night (top at 3PM) have more chance to happen fraud-transactions.</li>
</ol>
</br>

## Transaction's Amount Density Chart

```{r transAmountPlot, fig.width=10, warning=FALSE, fig.height=5}
ggplot(DisplayData, aes(x = Amount, fill = Class)) +
  geom_density(alpha = 0.4) +
  scale_x_continuous(limits = c(0, 500), breaks = seq(0, 500, 100)) + 
  labs(title = "Transaction Amount", 
       x = "Amount", 
       y = "Density", 
       col = "Class") + 
  scale_fill_discrete(labels = c("Fraud", "Not Fraud"))
```
</br>
- Evaluation:
<ol>
  <li>In the chart, the fraud transaction value from <b>90 to over 100</b> and <b>300 to 350</b> are way more density than the non-fraud transaction.</li> 
  <li>Hypothesis: Fraud transaction may happen to be large transaction (higher proportion of fraudulent transactions take a very large value).</li>
</ol>

## Predictive Model Using Decision Tree

- Decision tree learning uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves).
- Using rpart()function of rpart package in R to construct our Decision Tree and Predictive Model.

## Decision Tree Model 1

- Build the Decision tree Model using the train data subset from the original data
- Methods used is classification with the minimum number of bucket is 20.
```{r decisionTreeResult}
#Decision tree model
tree.model <-
  rpart(Class ~ .,
        data = train,
        method = "class",
        minbucket = 20)
prp(tree.model)
tree.predict <- predict(tree.model, cv, type = "class")
confusionMatrix(as.factor(cv$Class), tree.predict)

# Result
# 99.93 % accuracy using decision tree Model 1.
```

## Decision Tree Model 1 Evaluation

- Simply test the model by compare the Class column in test(cv) dataset
- Also collect the mean in percentage of the test to compare with the model
- Achieve an accurate of 99.93% (test with the subset data)
```{r decisionTreeEvaluation1, echo=TRUE}
# This function simply test the accurate of the model by compare the predicting model with the data 
mean(tree.predict == cv$Class) 
```
- Achieve an accurate of 95.25298% (test with the subset data)
```{r decisionTreeEvaluation2, echo=TRUE}
# This function simply test the accurate of the model by compare the predicting model with the data 
mean(tree.predict == subsetData$Class) 
```
- Achieve accuracy percentage of <b>99.93% and 95.25298% </b> which is match with the decision tree model accuracy percentage that found above. Prove that the decision tree model 1 is <b>accurate</b>.

## Decision Tree Model 2

- Build the Decision tree Model using the train data subset from the sampling subset data.
- Methods used is classification with the minimum number of bucket is 20 with the minimum number of bucket is 20.
```{r decisionTree2Result}
#Decision tree model
tree.model.2 <-
  rpart(Class ~ .,
        data = train.subset,
        method = "class",
        minbucket = 20)
prp(tree.model.2)
tree.predict.2 <- predict(tree.model.2, cv.subset, type = "class")
confusionMatrix(as.factor(cv.subset$Class), tree.predict.2)

# Result
# 99.97 % accuracy (best) using decision tree.
```

## Decision Tree Model 2 Evaluation

- Simply test the model by compare the Class column in test(cv.subset) dataset 
- Also collect the mean in percentage of the test to compare with the model
- Achieve an accurate of 99.97% (test with the subset data)
```{r decisionTreeEvaluation3, echo=TRUE}
# This function simply test the accurate of the model by compare the predicting model with the data 
mean(tree.predict.2 == cv.subset$Class) 
```
- Achieve an accurate of 95.20031% (test with the original test data set)
```{r decisionTreeEvaluation4, echo=TRUE}
# This function simply test the accurate of the model by compare the predicting model with the data 
mean(tree.predict.2 == cv$Class) 
```
- Achieve an accurate of 95.19815% (test with the whole original data set)
```{r decisionTreeEvaluation5, echo=TRUE}
# This function simply test the accurate of the model by compare the predicting model with the data 
mean(tree.predict.2 == Rdata$Class) 
```
- Achieve accuracy percentage of <b>99.96823%,95.20031%, and 95.19815%</b>  which is match with the decision tree model accuracy percentage that found above. Prove that the decision tree model 2 is accurate

## Support-Vector Machines Model (SVMs)

- support-vector machines (SVMs) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis
- Build the SVM Model using the train data subset from the subset data
```{r svmResults}
svm.model <- svm(Class ~ ., data = train.subset, kernel = "radial", cost = 1, gamma = 0.1)
svm.predict <- predict(svm.model, cv.subset)
confusionMatrix(cv.subset$Class, svm.predict)

```
</br>

## SVM Evaluations

- Match the prediction Model with the test data to test the model
- In test 1, achieve an accurate of 98.60229% (test with the test data set of the subset data)
```{r svmEvaluation1, echo=TRUE}

#DisplayData$Class <- (ifelse(DisplayData$Class =="zero" ,0 ,1)) # creates issues later in caret if using 0, 1
#DisplayData$Class <- as.numeric(as.character( DisplayData$Class))
#plot(svm.model, data = DisplayData, Class~Amount+Time)

mean(svm.predict == cv.subset$Class) 
```
- In test 2, achieve an accurate of 96.55677% (test with the test data set of the original data)
```{r svmEvaluation2, echo=TRUE}
mean(svm.predict == cv$Class) 
```
- In test 3, achieve an accurate of 96.55486% (test with the test entire original data)
```{r svmEvaluation3, echo=TRUE}
mean(svm.predict == Rdata$Class)
```
- Achieve accuracy percentage of <b>98.6%, 96.6% and 96.6% </b> which is match with the SVM accuracy percentage that found above. Prove that the SVM model is <b>accurate</b>

## Predictive Models using Random Forest

- Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes or mean/average prediction of the individual trees
- Build the Random Forest Decision Tree Model using the train data subset from the subset data
```{r randomForestModel}
set.seed(100)
rf.model <- randomForest(Class ~ ., data = train.subset,
                         ntree = 2000, nodesize = 20)
rf.predict <- predict(rf.model, cv.subset)
confusionMatrix(cv.subset$Class, rf.predict)
```

## Random Forest Graph

```{r rfPlot,fig.width=10, fig.height=5}
varImpPlot(rf.model)
```

## Random Forest Evaluation

- <p>Match the prediction Model with the test data to test the model.</p>
- <p>In test 1, achieve an accurate of 100% (test with the test sub test of the subset data).</p>
```{r rfEvaluation1, echo=TRUE}
mean(rf.predict == cv.subset$Class)
```
- <p>In test 2, achieve an accurate of 95.16871% (test with the sub test of the original data ).</p>
```{r rfEvaluation2, echo=TRUE}
mean(rf.predict == cv$Class)
```
- <p>In test 3, achieve an accurate of 95.16655% (test with the entire original data ).</p>
```{r rfEvaluation3, echo=TRUE}
mean(rf.predict == Rdata$Class)
```
- Achieve accuracy percentage of <b>100%, 95.1% and 95.1% </b> which is match with the Random Forest accuracy percentage that found above. Prove that the Random Forest model is <b>accurate</b>.

## Unsucess Data Minning Algorithm

- Unsuccessful data mining algorithm that applying to this data set:
<ol>
  <li>Clustering Models using k means methods</li> 
  <li>General Linear Model (GLM)</li>
  <li>Other Clustering methods </li>
</ol>
</br>

## Conclusion

- Many data-mining methods have been tested and applied to the training dataset(fraud credit card). 
- Different approaches has been applied to analyze the interesting patterns in the data set. 
- Different approach to train data (split the data, create factor value, sampling from the original data.). 
- Unsuccessful data mining algorithm that applying to this data set:
<ol>
  <li>Clustering Models using k means methods</li> 
  <li>General Linear Model (GLM)</li>
  <li>Other Clustering methods </li>
</ol>
- Success approach include: 
<ol>
  <li>Random Forest Predictive Model <b>(100% test case)</b></li>
  <li>Regression Decision Tree Predictive Model <b>(2 models with 99.97% and 99.93% test case)</b></li>
  <li>Support-Vector Machines Models</li>
- Successfully represent 2 density-graph that the hypothesis can be made from there.
- Finally, the research models will be able to recognize and detect fraud transactions in the data set. 

## Refrence

<p>Kurgan, L., & Musilek, P.(n.d.) <i>A survey of Knowledge Discovery and Data Mining process models, The Knowledge Engineering Review</i>, Vol. 21:1, 1–24. Retrieved from http://biomine.cs.vcu.edu/papers/KER-KDDM2006.pdf </p>
<p>Macaraeg, R., (2019, Sep. 5)<i>Credit Card Fraud Detection: Staying Vigilant in the Virtual World.</i> Retrieved from: https://towardsdatascience.com/credit-card-fraud-detection-a1c7e1b75f59 </p>
<p>Machine Learning Group,(2018)<i>Credit Card Fraud Detection: Anonymized credit card transactions labeled as fraudulent or genuine.</i> Retrieved from: https://www.kaggle.com/mlg-ulb/creditcardfraud </p>
<p>Patil. S., Nemade. V., & Soni, P. (2018)  <i>International Conference on Computational Intelligence and Data Science. Predictive Modelling For Credit Card Fraud Detection Using Data Analytics.</i> Retrieved from https://www.researchgate.net/publication/325663203_Predictive_Modelling_For_Credit_Card_Fraud_Detection_Using_Data_Analytic</p>
<p>Pozzolo A., Caelen O., Johnson R. & Bontempi G.(2015) <i>Calibrating Probability with Undersampling for Unbalanced Classification.</i> In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE</p>
<p>Pozzolo A.; Olivier C.; Yann-Ael B.; Serge; Gianluca B.(2014) <i>Learned lessons in credit card fraud detection from a practitioner perspective, Expert systems with applications</i>,41,10,4915-4928, Pergamon</p>
<p>Preda. G., (2020) Credit Card Fraud Detection Predictive Models. Retrieved from https://www.kaggle.com/gpreda/credit-card-fraud-detection-predictive-models</p>
<p>Sanagapati. P., (2019) Anomaly Detection - Credit Card Fraud Analysis. Retrieved from https://www.kaggle.com/pavansanagapati/anomaly-detection-credit-card-fraud-analysis</p>
<p>Visallo (n.d.) <i>Credit Card Fraud Detection 2019</i> Retrieved from https://www.visallo.com/blog/credit-card-fraud-detection-2019/</p>